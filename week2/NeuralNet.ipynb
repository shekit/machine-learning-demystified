{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#step 1 input data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 1 continues .. define my placeholders\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "actual_y = tf.placeholder(tf.float32, [None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# step 2 - randomly initialize weights\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]), tf.float32)\n",
    "b = tf.Variable(tf.zeros([10]), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 3 - define my model\n",
    "\n",
    "predicted_y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4 - Error\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=actual_y, logits=predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 5 - perform gradient descent\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize our session\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    batch_x, batch_y = mnist.train.next_batch(100)\n",
    "    sess.run(optimizer, feed_dict={x:batch_x, actual_y:batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input your own image here of a handwritten number, cropped to 28x28 pixels\n",
    "\n",
    "three = imread('3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x124de5400>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124d539b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#it should look like the one below\n",
    "plt.imshow(three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the helper function written in utils.py to convert \n",
    "# the image into an array which is 784 pixels long\n",
    "\n",
    "new_img = utils.prepImage('3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.63368487,  -0.87597883,   1.92645037,  12.21197319,\n",
       "         -6.50765467,   3.94136453,  -4.8993907 ,  -6.61414719,\n",
       "          5.0830431 ,  -0.63196325]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed this new image array into the trained model\n",
    "# and see the highest output - thats what it predicted\n",
    "\n",
    "sess.run(predicted_y, feed_dict={x: new_img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = sess.run(predicted_y, feed_dict={x: new_img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soft = tf.nn.softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.argmax(soft, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
